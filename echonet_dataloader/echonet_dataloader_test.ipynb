{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d8a5fe65-549b-4a2e-ac45-b60f2b11b2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"EchoNet-Dynamic Dataset.\"\"\"\n",
    "\n",
    "import os\n",
    "import collections\n",
    "import pandas\n",
    "import torch\n",
    "import numpy as np\n",
    "import skimage.draw\n",
    "import torchvision\n",
    "import echonet_dataloader\n",
    "from echonet_dataloader.deformation.utils import *\n",
    "\n",
    "class Echo(torchvision.datasets.VisionDataset):\n",
    "    def __init__(self, root=None,\n",
    "                 split=\"train\", target_type=\"EF\",\n",
    "                 mean=0., std=1.,\n",
    "                 length=16, period=2,\n",
    "                 fixed_length=16, max_length=250,\n",
    "                 clips=1,\n",
    "                 self_supervised = False):\n",
    "\n",
    "\n",
    "        super().__init__(root)\n",
    "        self.root = root\n",
    "        self.split = split.upper()\n",
    "        if not isinstance(target_type, list):\n",
    "            target_type = [target_type]\n",
    "        self.target_type = target_type\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.length = length\n",
    "        self.max_length = max_length\n",
    "        self.period = period\n",
    "        self.clips = clips\n",
    "        self.fnames, self.outcome , self.ejection  = [], [] , []\n",
    "        self.fixed_length = fixed_length\n",
    "\n",
    "\n",
    "        # Load video-level labels\n",
    "        # Read csv file\n",
    "        with open(os.path.join(self.root, \"FileList.csv\")) as f:\n",
    "            data = pandas.read_csv(f)\n",
    "            \n",
    "        # Make all TRAIN,VAl and TEST upper\n",
    "        data[\"Split\"].map(lambda x: x.upper())\n",
    "        \n",
    "        \n",
    "        # Split = Train , Val or Test\n",
    "        if self.split != \"ALL\":\n",
    "            \n",
    "            data = data[data[\"Split\"] == self.split]\n",
    "            self.header = data.columns.tolist()\n",
    "            self.fnames = data[\"FileName\"].tolist()\n",
    "            # File names with suffix (.avi)\n",
    "            self.fnames = [fn + \".avi\" for fn in self.fnames if os.path.splitext(fn)[1] == \"\"]  # Assume avi if no suffix\n",
    "            self.outcome = data.values.tolist()\n",
    "\n",
    "            \n",
    "            \n",
    "            # Check that files are present\n",
    "            missing = set(self.fnames) - set(os.listdir(os.path.join(self.root, \"Videos\")))\n",
    "            if len(missing) != 0:\n",
    "                print(\"{} videos could not be found in {}:\".format(len(missing), os.path.join(self.root, \"Videos\")))\n",
    "                for f in sorted(missing):\n",
    "                    print(\"\\t\", f)\n",
    "                raise FileNotFoundError(os.path.join(self.root, \"Videos\", sorted(missing)[0]))\n",
    "\n",
    "            # Load traces\n",
    "            self.frames = collections.defaultdict(list)\n",
    "            self.trace = collections.defaultdict(_defaultdict_of_lists)\n",
    "\n",
    "            \n",
    "            # Open VolumeTracings.csv\n",
    "            with open(os.path.join(self.root, \"VolumeTracings.csv\")) as f:\n",
    "                header = f.readline().strip().split(\",\")\n",
    "                assert header == [\"FileName\", \"X1\", \"Y1\", \"X2\", \"Y2\", \"Frame\"]\n",
    "\n",
    "                for line in f:\n",
    "                    filename, x1, y1, x2, y2, frame = line.strip().split(',')\n",
    "                    x1 = float(x1)\n",
    "                    y1 = float(y1)\n",
    "                    x2 = float(x2)\n",
    "                    y2 = float(y2)\n",
    "                    frame = int(frame)\n",
    "                    \n",
    "                    # New frame index for the given filename\n",
    "                    if frame not in self.trace[filename]:\n",
    "                        self.frames[filename].append(frame)\n",
    "                        \n",
    "                     # Add volume lines to trace\n",
    "                    self.trace[filename][frame].append((x1, y1, x2, y2))\n",
    "                    \n",
    "                    \n",
    "            # Changing the format to numpy array\n",
    "            for filename in self.frames:\n",
    "                for frame in self.frames[filename]:\n",
    "                    self.trace[filename][frame] = np.array(self.trace[filename][frame])\n",
    "\n",
    "                    \n",
    "            # A small number of videos are missing traces; remove these videos\n",
    "            keep = [len(self.frames[f]) >= 2 for f in self.fnames]\n",
    "            \n",
    "            # Prepare for getitem\n",
    "            self.fnames = [f for (f, k) in zip(self.fnames, keep) if k]\n",
    "            self.outcome = [f for (f, k) in zip(self.outcome, keep) if k]\n",
    "            self.self_supervised = self_supervised\n",
    "            self.conf = conf\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        # Find filename of video\n",
    "        path = os.path.join(self.root, \"Videos\", self.fnames[index])\n",
    "\n",
    "        # Load video into np.array\n",
    "        video = echonet_dataloader.utils.loadvideo(path).astype(np.float32)\n",
    "\n",
    "\n",
    "        # Scale pixel values from 0-255 to 0-1\n",
    "        video /= 255.0\n",
    "        # video = np.moveaxis(video, 0, 1)\n",
    "\n",
    "        # Set number of frames\n",
    "        c, f, h, w = video.shape\n",
    "        \n",
    "        \n",
    "        # index of ED and ES \n",
    "        key = self.fnames[index]\n",
    "        samp_size = abs(self.frames[key][0]-self.frames[key][-1])\n",
    "\n",
    "        large_key = self.frames[key][-1]\n",
    "        small_key = self.frames[key][0]\n",
    "            \n",
    "        # Index of first and last frame with segmentation\n",
    "        first_poi = min(small_key, large_key)\n",
    "        last_poi  = max(small_key, large_key)\n",
    "        dist = abs(small_key-large_key) \n",
    "        \n",
    "        # Label of frames \n",
    "        label  = np.zeros(f)\n",
    "        label[small_key] = 1 # End systole (small)\n",
    "        label[large_key] = 2 # End diastole (large)\n",
    "\n",
    "            \n",
    "\n",
    "        # Gather targets\n",
    "        target = []\n",
    "        for t in self.target_type:\n",
    "            key = self.fnames[index]\n",
    "            if t == \"LargeFrame\":\n",
    "                target.append(video[:, self.frames[key][-1], :, :])\n",
    "            elif t == \"SmallFrame\":\n",
    "                target.append(video[:, self.frames[key][0], :, :])\n",
    "            elif t in [\"LargeTrace\", \"SmallTrace\"]:\n",
    "                if t == \"LargeTrace\":\n",
    "                    t = self.trace[key][self.frames[key][-1]]\n",
    "                else:\n",
    "                    t = self.trace[key][self.frames[key][0]]\n",
    "                x1, y1, x2, y2 = t[:, 0], t[:, 1], t[:, 2], t[:, 3]\n",
    "                x = np.concatenate((x1[1:], np.flip(x2[1:])))\n",
    "                y = np.concatenate((y1[1:], np.flip(y2[1:])))\n",
    "\n",
    "                r, c = skimage.draw.polygon(np.rint(y).astype(np.int), np.rint(x).astype(np.int), (video.shape[2], video.shape[3]))\n",
    "                mask = np.zeros((video.shape[2], video.shape[3]), np.float32)\n",
    "                mask[r, c] = 1\n",
    "                target.append(torch.tensor(mask))\n",
    "            else:\n",
    "                if self.split == \"CLINICAL_TEST\" or self.split == \"EXTERNAL_TEST\":\n",
    "                    target.append(torch.tensor(np.float32(0)))\n",
    "                else:\n",
    "                    target.append(torch.tensor(np.float32(self.outcome[index][self.header.index(t)])))\n",
    "\n",
    "\n",
    "        # Gather Video\n",
    "        if dist<length:\n",
    "            # Take random clips from video\n",
    "            pre_start = int((length - dist)//2)\n",
    "            start_index = int(max(0, first_poi - pre_start))  \n",
    "            end_index = start_index + length \n",
    "            video = video[:,start_index : end_index, :, :]\n",
    "            label = label[start_index:end_index]\n",
    "        \n",
    "        else:\n",
    "            divider     = np.random.random_sample()*5+2\n",
    "            start_index = first_poi - dist//divider\n",
    "            start_index = int(max(0, start_index)//2*2)             \n",
    "            divider     = np.random.random_sample()*5+2\n",
    "            end_index   = last_poi +1 + dist//divider #+1 to INCLUDE the frame\n",
    "            end_index   = int(min(f, end_index)//2*2)\n",
    "            step = int( np.ceil((end_index-start_index)/ length) )\n",
    "            list_frame = np.arange(first_poi, last_poi , step, dtype=int)\n",
    "            list_frame = np.append(list_frame, last_poi)\n",
    "            list_all = np.arange(start_index,end_index)\n",
    "            np.random.shuffle(list_all)\n",
    "            list_frame  = np.sort(np.append(list_frame,list_all[:(length - len(list_frame))]))\n",
    "            video = video[:,list_frame, :, :]\n",
    "            label = label[list_frame]\n",
    "                \n",
    "        if self.self_supervised:\n",
    "            deform = generate_pair_d(video,1, self.conf)\n",
    "            #cine_d = torch.as_tensor(np.array(deform).astype('float'))\n",
    "            return video,deform,label,target\n",
    "            \n",
    "        return video,label, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fnames)\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        \"\"\"Additional information to add at end of __repr__.\"\"\"\n",
    "        lines = [\"Target type: {target_type}\", \"Split: {split}\"]\n",
    "        return '\\n'.join(lines).format(**self.__dict__)\n",
    "\n",
    "\n",
    "def _defaultdict_of_lists():\n",
    "    \"\"\"Returns a defaultdict of lists.\n",
    "\n",
    "    This is used to avoid issues with Windows (if this function is anonymous,\n",
    "    the Echo dataset cannot be used in a dataloader).\n",
    "    \"\"\"\n",
    "\n",
    "    return collections.defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "855688bd-a661-4129-a020-2f6e54c9ed07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>FileName</th>\n",
       "      <th>EF</th>\n",
       "      <th>ESV</th>\n",
       "      <th>EDV</th>\n",
       "      <th>FrameHeight</th>\n",
       "      <th>FrameWidth</th>\n",
       "      <th>FPS</th>\n",
       "      <th>NumberOfFrames</th>\n",
       "      <th>Split</th>\n",
       "      <th>EDFrame</th>\n",
       "      <th>ESFrame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0X100009310A3BD7FC</td>\n",
       "      <td>78.498406</td>\n",
       "      <td>14.881368</td>\n",
       "      <td>69.210534</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>50</td>\n",
       "      <td>174</td>\n",
       "      <td>VAL</td>\n",
       "      <td>46.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0X1002E8FBACD08477</td>\n",
       "      <td>59.101988</td>\n",
       "      <td>40.383876</td>\n",
       "      <td>98.742884</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>50</td>\n",
       "      <td>215</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0X1005D03EED19C65B</td>\n",
       "      <td>62.363798</td>\n",
       "      <td>14.267784</td>\n",
       "      <td>37.909734</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>50</td>\n",
       "      <td>104</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0X10075961BC11C88E</td>\n",
       "      <td>54.545097</td>\n",
       "      <td>33.143084</td>\n",
       "      <td>72.914210</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>55</td>\n",
       "      <td>122</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>91.0</td>\n",
       "      <td>108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0X10094BA0A028EAC3</td>\n",
       "      <td>24.887742</td>\n",
       "      <td>127.581945</td>\n",
       "      <td>169.855024</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>52</td>\n",
       "      <td>207</td>\n",
       "      <td>VAL</td>\n",
       "      <td>137.0</td>\n",
       "      <td>156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10025</th>\n",
       "      <td>10025</td>\n",
       "      <td>0X234005774F4CB5CD</td>\n",
       "      <td>51.724743</td>\n",
       "      <td>47.065329</td>\n",
       "      <td>97.493690</td>\n",
       "      <td>768</td>\n",
       "      <td>1040</td>\n",
       "      <td>50</td>\n",
       "      <td>127</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10026</th>\n",
       "      <td>10026</td>\n",
       "      <td>0X2DC68261CBCC04AE</td>\n",
       "      <td>62.187781</td>\n",
       "      <td>26.333478</td>\n",
       "      <td>69.642772</td>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "      <td>50</td>\n",
       "      <td>66</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10027</th>\n",
       "      <td>10027</td>\n",
       "      <td>0X35291BE9AB90FB89</td>\n",
       "      <td>62.070762</td>\n",
       "      <td>49.064338</td>\n",
       "      <td>129.357561</td>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "      <td>50</td>\n",
       "      <td>208</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10028</th>\n",
       "      <td>10028</td>\n",
       "      <td>0X6C435C1B417FDE8A</td>\n",
       "      <td>59.635257</td>\n",
       "      <td>57.721170</td>\n",
       "      <td>142.998978</td>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "      <td>50</td>\n",
       "      <td>166</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10029</th>\n",
       "      <td>10029</td>\n",
       "      <td>0X5515B0BD077BE68A</td>\n",
       "      <td>46.019994</td>\n",
       "      <td>27.260394</td>\n",
       "      <td>50.500910</td>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "      <td>50</td>\n",
       "      <td>126</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10030 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0            FileName         EF         ESV         EDV  \\\n",
       "0               0  0X100009310A3BD7FC  78.498406   14.881368   69.210534   \n",
       "1               1  0X1002E8FBACD08477  59.101988   40.383876   98.742884   \n",
       "2               2  0X1005D03EED19C65B  62.363798   14.267784   37.909734   \n",
       "3               3  0X10075961BC11C88E  54.545097   33.143084   72.914210   \n",
       "4               4  0X10094BA0A028EAC3  24.887742  127.581945  169.855024   \n",
       "...           ...                 ...        ...         ...         ...   \n",
       "10025       10025  0X234005774F4CB5CD  51.724743   47.065329   97.493690   \n",
       "10026       10026  0X2DC68261CBCC04AE  62.187781   26.333478   69.642772   \n",
       "10027       10027  0X35291BE9AB90FB89  62.070762   49.064338  129.357561   \n",
       "10028       10028  0X6C435C1B417FDE8A  59.635257   57.721170  142.998978   \n",
       "10029       10029  0X5515B0BD077BE68A  46.019994   27.260394   50.500910   \n",
       "\n",
       "       FrameHeight  FrameWidth  FPS  NumberOfFrames  Split  EDFrame  ESFrame  \n",
       "0              112         112   50             174    VAL     46.0     61.0  \n",
       "1              112         112   50             215  TRAIN      3.0     18.0  \n",
       "2              112         112   50             104  TRAIN     24.0     35.0  \n",
       "3              112         112   55             122  TRAIN     91.0    108.0  \n",
       "4              112         112   52             207    VAL    137.0    156.0  \n",
       "...            ...         ...  ...             ...    ...      ...      ...  \n",
       "10025          768        1040   50             127  TRAIN      NaN      NaN  \n",
       "10026          768        1024   50              66  TRAIN      NaN      NaN  \n",
       "10027          768        1024   50             208  TRAIN      NaN      NaN  \n",
       "10028          768        1024   50             166  TRAIN      NaN      NaN  \n",
       "10029          768        1024   50             126  TRAIN      NaN      NaN  \n",
       "\n",
       "[10030 rows x 12 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = '/AS_Neda/echonet/'\n",
    "with open(os.path.join(root, \"FileList.csv\")) as f:\n",
    "    data = pandas.read_csv(f)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "09dc5902-913c-4241-a577-ef093bd51a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import echonet_dataloader\n",
    "from echonet_dataloader import utils\n",
    "from config import models_genesis_config\n",
    "from get_config_genesis import get_config\n",
    "import os\n",
    "from config import models_genesis_config\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,7\"\n",
    "\n",
    "conf = models_genesis_config()\n",
    "config = get_config()\n",
    "tasks = ['EF','SmallFrame' , 'LargeFrame', 'SmallTrace' ,'LargeTrace']\n",
    "kwargs = {\"target_type\": tasks,\n",
    "          \"mean\": 0,\n",
    "          \"std\": 1,\n",
    "          \"self_supervised\":True\n",
    "          }\n",
    "traindataset = Echo(root='/AS_Neda/echonet/', split=\"train\",**kwargs)\n",
    "#train_loader = torch.utils.data.DataLoader(\n",
    "#                    traindataset, batch_size=16, num_workers=4, shuffle=True, pin_memory=True, drop_last=True)\n",
    "#video,target = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "df212f89-47d1-41d8-b1cf-c59e22c50a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 16, 112, 112)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video,deform,label,target = traindataset[750]\n",
    "deform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3b3275-4559-4094-b787-b03c5e8840a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rc\n",
    "rc('animation', html='jshtml')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "video,deform,label,target = traindataset[750]\n",
    "print('label',label)\n",
    "video = (np.array(deform)).transpose((1,2,3,0))\n",
    "frames = [[ax.imshow(video[i],cmap='gray')] for i in range(len(video))]\n",
    "ani = animation.ArtistAnimation(fig, frames)\n",
    "ani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2f6413-7605-4ebc-b97d-8843a927a6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained segmentation model\n",
    "model_s = torchvision.models.segmentation.deeplabv3_resnet50(aux_loss=False)\n",
    "model_s.classifier[-1] = torch.nn.Conv2d(model_s.classifier[-1].in_channels, 1, kernel_size=model_s.classifier[-1].kernel_size)\n",
    "if device.type == \"cuda\":\n",
    "    model_s = torch.nn.DataParallel(model_s)\n",
    "model_s.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
